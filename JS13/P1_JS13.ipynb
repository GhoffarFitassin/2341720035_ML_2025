{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Praktikum 1"
      ],
      "metadata": {
        "id": "Te25ZvWKSqxz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyWGMaO6SdzS",
        "outputId": "2d77532c-a84e-43ff-dcc5-df060e45d5d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.25524583607840745\n",
            "Epoch 1000, Loss: 0.2500107032468195\n",
            "Epoch 2000, Loss: 0.2499630715529133\n",
            "Epoch 3000, Loss: 0.24988843594263688\n",
            "Epoch 4000, Loss: 0.24966589242882556\n",
            "Epoch 5000, Loss: 0.2487766715834715\n",
            "Epoch 6000, Loss: 0.24312975489928426\n",
            "Epoch 7000, Loss: 0.21276406806177237\n",
            "Epoch 8000, Loss: 0.15522311355085394\n",
            "Epoch 9000, Loss: 0.05175774717755194\n",
            "Prediksi:\n",
            "[[0.14673223]\n",
            " [0.84648375]\n",
            " [0.83319328]\n",
            " [0.12951705]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# Parameter\n",
        "input_size = 2\n",
        "hidden_size = 2\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Fungsi aktivasi\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Training\n",
        "for epoch in range(10000):\n",
        "    # Forward pass\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # Hitung error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update bobot\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Output akhir\n",
        "print(\"Prediksi:\")\n",
        "print(a2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tugas 1:\n",
        "- Ubah jumlah neuron hidden layer menjadi 3.\n",
        "- Bandingkan hasil loss dengan konfigurasi awal.\n",
        "- Tambahkan fungsi aktivasi ReLU dan bandingkan hasil.\n",
        "\n"
      ],
      "metadata": {
        "id": "_jm3_bt5Sz5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Agar hasil konsisten (reproducible)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# --- PERUBAHAN TUGAS 1 ---\n",
        "# Mengubah hidden_size dari 2 menjadi 3\n",
        "input_size = 2\n",
        "hidden_size = 3\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Fungsi aktivasi (Sigmoid)\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "print(\"--- TRAINING DENGAN 3 HIDDEN NEURONS (SIGMOID) ---\")\n",
        "# Training\n",
        "for epoch in range(10001):\n",
        "    # Forward pass\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # Hitung error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update bobot\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 2000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.6f}\")\n",
        "\n",
        "# Output akhir\n",
        "print(\"\\nPrediksi Akhir:\")\n",
        "print(a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPPTAjdUSzmh",
        "outputId": "f021fdc3-12ec-4b96-c8e9-edb2a559b42e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TRAINING DENGAN 3 HIDDEN NEURONS (SIGMOID) ---\n",
            "Epoch 0, Loss: 0.318245\n",
            "Epoch 2000, Loss: 0.141854\n",
            "Epoch 4000, Loss: 0.020112\n",
            "Epoch 6000, Loss: 0.006270\n",
            "Epoch 8000, Loss: 0.003421\n",
            "Epoch 10000, Loss: 0.002297\n",
            "\n",
            "Prediksi Akhir:\n",
            "[[0.02515318]\n",
            " [0.95264015]\n",
            " [0.95122762]\n",
            " [0.06271949]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# Parameter\n",
        "input_size = 2\n",
        "hidden_size = 3 # Tetap pakai 3 agar adil perbandingannya\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# --- FUNGSI AKTIVASI BARU (RELU) ---\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    # Turunan ReLU adalah 1 jika x > 0, selain itu 0\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "# Sigmoid tetap dipakai untuk Output Layer\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "print(\"--- TRAINING DENGAN RELU (HIDDEN) & SIGMOID (OUTPUT) ---\")\n",
        "\n",
        "# Training\n",
        "for epoch in range(10001):\n",
        "    # Forward pass\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = relu(z1)      # <--- GANTI JADI RELU\n",
        "\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)   # Output tetap Sigmoid\n",
        "\n",
        "    # Hitung error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation\n",
        "\n",
        "    # Layer 2 (Output) - Tetap pakai turunan Sigmoid\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    # Layer 1 (Hidden) - GANTI JADI TURUNAN RELU\n",
        "    # Kita gunakan z1 untuk cek turunan ReLU (apakah input > 0)\n",
        "    d_a1 = np.dot(d_a2, W2.T) * relu_derivative(z1)\n",
        "\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update bobot\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 2000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.6f}\")\n",
        "\n",
        "print(\"\\nPrediksi Akhir (ReLU):\")\n",
        "print(a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN73IJ3pWmTn",
        "outputId": "1e0d6041-a126-4124-8956-aa3692c3d58f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TRAINING DENGAN RELU (HIDDEN) & SIGMOID (OUTPUT) ---\n",
            "Epoch 0, Loss: 0.327478\n",
            "Epoch 2000, Loss: 0.003283\n",
            "Epoch 4000, Loss: 0.001147\n",
            "Epoch 6000, Loss: 0.000666\n",
            "Epoch 8000, Loss: 0.000462\n",
            "Epoch 10000, Loss: 0.000351\n",
            "\n",
            "Prediksi Akhir (ReLU):\n",
            "[[0.02969834]\n",
            " [0.98607299]\n",
            " [0.98607278]\n",
            " [0.0116511 ]]\n"
          ]
        }
      ]
    }
  ]
}